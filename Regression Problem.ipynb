{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2   3      4      5     6       7   8      9     10      11    12    13\n",
       "0    0.00632  18.0   2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3  396.90  4.98  24.0\n",
       "1    0.02731   0.0   7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8  396.90  9.14  21.6\n",
       "2    0.02729   0.0   7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8  392.83  4.03  34.7\n",
       "3    0.03237   0.0   2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7  394.63  2.94  33.4\n",
       "4    0.06905   0.0   2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7  396.90  5.33  36.2\n",
       "..       ...   ...    ...  ..    ...    ...   ...     ...  ..    ...   ...     ...   ...   ...\n",
       "501  0.06263   0.0  11.93   0  0.573  6.593  69.1  2.4786   1  273.0  21.0  391.99  9.67  22.4\n",
       "502  0.04527   0.0  11.93   0  0.573  6.120  76.7  2.2875   1  273.0  21.0  396.90  9.08  20.6\n",
       "503  0.06076   0.0  11.93   0  0.573  6.976  91.0  2.1675   1  273.0  21.0  396.90  5.64  23.9\n",
       "504  0.10959   0.0  11.93   0  0.573  6.794  89.3  2.3889   1  273.0  21.0  393.45  6.48  22.0\n",
       "505  0.04741   0.0  11.93   0  0.573  6.030  80.8  2.5050   1  273.0  21.0  396.90  7.88  11.9\n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "df = read_csv(path, header = None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       506 non-null    float64\n",
      " 1   1       506 non-null    float64\n",
      " 2   2       506 non-null    float64\n",
      " 3   3       506 non-null    int64  \n",
      " 4   4       506 non-null    float64\n",
      " 5   5       506 non-null    float64\n",
      " 6   6       506 non-null    float64\n",
      " 7   7       506 non-null    float64\n",
      " 8   8       506 non-null    int64  \n",
      " 9   9       506 non-null    float64\n",
      " 10  10      506 non-null    float64\n",
      " 11  11      506 non-null    float64\n",
      " 12  12      506 non-null    float64\n",
      " 13  13      506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "X,y = df.values[:,:-1], df.values[:,-1]\n",
    "print(X.shape , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 13) (167, 13) (339,) (167,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1)) # 'lecun_normal' and 'selu' (initializer and A.F) proves to do well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "34/34 - 1s - loss: 35249.6328\n",
      "Epoch 2/150\n",
      "34/34 - 0s - loss: 7213.5649\n",
      "Epoch 3/150\n",
      "34/34 - 0s - loss: 1009.9541\n",
      "Epoch 4/150\n",
      "34/34 - 0s - loss: 408.2719\n",
      "Epoch 5/150\n",
      "34/34 - 0s - loss: 374.8961\n",
      "Epoch 6/150\n",
      "34/34 - 0s - loss: 345.5216\n",
      "Epoch 7/150\n",
      "34/34 - 0s - loss: 315.5071\n",
      "Epoch 8/150\n",
      "34/34 - 0s - loss: 289.9481\n",
      "Epoch 9/150\n",
      "34/34 - 0s - loss: 264.4096\n",
      "Epoch 10/150\n",
      "34/34 - 0s - loss: 240.2699\n",
      "Epoch 11/150\n",
      "34/34 - 0s - loss: 220.0766\n",
      "Epoch 12/150\n",
      "34/34 - 0s - loss: 199.9567\n",
      "Epoch 13/150\n",
      "34/34 - 0s - loss: 183.0859\n",
      "Epoch 14/150\n",
      "34/34 - 0s - loss: 168.4800\n",
      "Epoch 15/150\n",
      "34/34 - 0s - loss: 153.5506\n",
      "Epoch 16/150\n",
      "34/34 - 0s - loss: 141.0909\n",
      "Epoch 17/150\n",
      "34/34 - 0s - loss: 130.2325\n",
      "Epoch 18/150\n",
      "34/34 - 0s - loss: 121.2760\n",
      "Epoch 19/150\n",
      "34/34 - 0s - loss: 112.0668\n",
      "Epoch 20/150\n",
      "34/34 - 0s - loss: 104.9521\n",
      "Epoch 21/150\n",
      "34/34 - 0s - loss: 97.8502\n",
      "Epoch 22/150\n",
      "34/34 - 0s - loss: 93.0915\n",
      "Epoch 23/150\n",
      "34/34 - 0s - loss: 88.3291\n",
      "Epoch 24/150\n",
      "34/34 - 0s - loss: 84.9824\n",
      "Epoch 25/150\n",
      "34/34 - 0s - loss: 81.7145\n",
      "Epoch 26/150\n",
      "34/34 - 0s - loss: 79.7369\n",
      "Epoch 27/150\n",
      "34/34 - 0s - loss: 78.3547\n",
      "Epoch 28/150\n",
      "34/34 - 0s - loss: 75.5671\n",
      "Epoch 29/150\n",
      "34/34 - 0s - loss: 74.1734\n",
      "Epoch 30/150\n",
      "34/34 - 0s - loss: 73.2484\n",
      "Epoch 31/150\n",
      "34/34 - 0s - loss: 72.2735\n",
      "Epoch 32/150\n",
      "34/34 - 0s - loss: 71.6654\n",
      "Epoch 33/150\n",
      "34/34 - 0s - loss: 71.4423\n",
      "Epoch 34/150\n",
      "34/34 - 0s - loss: 70.3139\n",
      "Epoch 35/150\n",
      "34/34 - 0s - loss: 69.9437\n",
      "Epoch 36/150\n",
      "34/34 - 0s - loss: 68.6112\n",
      "Epoch 37/150\n",
      "34/34 - 0s - loss: 68.5669\n",
      "Epoch 38/150\n",
      "34/34 - 0s - loss: 68.6006\n",
      "Epoch 39/150\n",
      "34/34 - 0s - loss: 67.7169\n",
      "Epoch 40/150\n",
      "34/34 - 0s - loss: 67.2898\n",
      "Epoch 41/150\n",
      "34/34 - 0s - loss: 66.8861\n",
      "Epoch 42/150\n",
      "34/34 - 0s - loss: 66.7843\n",
      "Epoch 43/150\n",
      "34/34 - 0s - loss: 65.8174\n",
      "Epoch 44/150\n",
      "34/34 - 0s - loss: 66.0669\n",
      "Epoch 45/150\n",
      "34/34 - 0s - loss: 65.3176\n",
      "Epoch 46/150\n",
      "34/34 - 0s - loss: 64.5426\n",
      "Epoch 47/150\n",
      "34/34 - 0s - loss: 64.7630\n",
      "Epoch 48/150\n",
      "34/34 - 0s - loss: 65.2355\n",
      "Epoch 49/150\n",
      "34/34 - 0s - loss: 64.2402\n",
      "Epoch 50/150\n",
      "34/34 - 0s - loss: 62.9781\n",
      "Epoch 51/150\n",
      "34/34 - 0s - loss: 63.3166\n",
      "Epoch 52/150\n",
      "34/34 - 0s - loss: 63.8185\n",
      "Epoch 53/150\n",
      "34/34 - 0s - loss: 63.5658\n",
      "Epoch 54/150\n",
      "34/34 - 0s - loss: 62.7849\n",
      "Epoch 55/150\n",
      "34/34 - 0s - loss: 63.6058\n",
      "Epoch 56/150\n",
      "34/34 - 0s - loss: 61.5222\n",
      "Epoch 57/150\n",
      "34/34 - 0s - loss: 61.4088\n",
      "Epoch 58/150\n",
      "34/34 - 0s - loss: 61.9799\n",
      "Epoch 59/150\n",
      "34/34 - 0s - loss: 61.0043\n",
      "Epoch 60/150\n",
      "34/34 - 0s - loss: 60.8961\n",
      "Epoch 61/150\n",
      "34/34 - 0s - loss: 59.8327\n",
      "Epoch 62/150\n",
      "34/34 - 0s - loss: 59.8453\n",
      "Epoch 63/150\n",
      "34/34 - 0s - loss: 59.1566\n",
      "Epoch 64/150\n",
      "34/34 - 0s - loss: 58.7168\n",
      "Epoch 65/150\n",
      "34/34 - 0s - loss: 59.3222\n",
      "Epoch 66/150\n",
      "34/34 - 0s - loss: 59.4744\n",
      "Epoch 67/150\n",
      "34/34 - 0s - loss: 58.2382\n",
      "Epoch 68/150\n",
      "34/34 - 0s - loss: 58.0180\n",
      "Epoch 69/150\n",
      "34/34 - 0s - loss: 57.5102\n",
      "Epoch 70/150\n",
      "34/34 - 0s - loss: 57.0102\n",
      "Epoch 71/150\n",
      "34/34 - 0s - loss: 57.4969\n",
      "Epoch 72/150\n",
      "34/34 - 0s - loss: 57.7261\n",
      "Epoch 73/150\n",
      "34/34 - 0s - loss: 57.4212\n",
      "Epoch 74/150\n",
      "34/34 - 0s - loss: 56.8253\n",
      "Epoch 75/150\n",
      "34/34 - 0s - loss: 56.1232\n",
      "Epoch 76/150\n",
      "34/34 - 0s - loss: 54.9849\n",
      "Epoch 77/150\n",
      "34/34 - 0s - loss: 57.0268\n",
      "Epoch 78/150\n",
      "34/34 - 0s - loss: 56.2058\n",
      "Epoch 79/150\n",
      "34/34 - 0s - loss: 54.1317\n",
      "Epoch 80/150\n",
      "34/34 - 0s - loss: 54.4372\n",
      "Epoch 81/150\n",
      "34/34 - 0s - loss: 54.6336\n",
      "Epoch 82/150\n",
      "34/34 - 0s - loss: 55.1578\n",
      "Epoch 83/150\n",
      "34/34 - 0s - loss: 54.9994\n",
      "Epoch 84/150\n",
      "34/34 - 0s - loss: 53.1131\n",
      "Epoch 85/150\n",
      "34/34 - 0s - loss: 54.4650\n",
      "Epoch 86/150\n",
      "34/34 - 0s - loss: 53.0133\n",
      "Epoch 87/150\n",
      "34/34 - 0s - loss: 51.7176\n",
      "Epoch 88/150\n",
      "34/34 - 0s - loss: 53.1699\n",
      "Epoch 89/150\n",
      "34/34 - 0s - loss: 54.1431\n",
      "Epoch 90/150\n",
      "34/34 - 0s - loss: 51.2127\n",
      "Epoch 91/150\n",
      "34/34 - 0s - loss: 50.7152\n",
      "Epoch 92/150\n",
      "34/34 - 0s - loss: 51.5699\n",
      "Epoch 93/150\n",
      "34/34 - 0s - loss: 51.0346\n",
      "Epoch 94/150\n",
      "34/34 - 0s - loss: 51.1617\n",
      "Epoch 95/150\n",
      "34/34 - 0s - loss: 50.0443\n",
      "Epoch 96/150\n",
      "34/34 - 0s - loss: 49.8788\n",
      "Epoch 97/150\n",
      "34/34 - 0s - loss: 49.9571\n",
      "Epoch 98/150\n",
      "34/34 - 0s - loss: 48.7691\n",
      "Epoch 99/150\n",
      "34/34 - 0s - loss: 48.5528\n",
      "Epoch 100/150\n",
      "34/34 - 0s - loss: 49.8064\n",
      "Epoch 101/150\n",
      "34/34 - 0s - loss: 49.5323\n",
      "Epoch 102/150\n",
      "34/34 - 0s - loss: 46.9378\n",
      "Epoch 103/150\n",
      "34/34 - 0s - loss: 47.5363\n",
      "Epoch 104/150\n",
      "34/34 - 0s - loss: 47.2087\n",
      "Epoch 105/150\n",
      "34/34 - 0s - loss: 48.7030\n",
      "Epoch 106/150\n",
      "34/34 - 0s - loss: 47.2161\n",
      "Epoch 107/150\n",
      "34/34 - 0s - loss: 47.6134\n",
      "Epoch 108/150\n",
      "34/34 - 0s - loss: 45.9606\n",
      "Epoch 109/150\n",
      "34/34 - 0s - loss: 45.7030\n",
      "Epoch 110/150\n",
      "34/34 - 0s - loss: 48.9027\n",
      "Epoch 111/150\n",
      "34/34 - 0s - loss: 46.7600\n",
      "Epoch 112/150\n",
      "34/34 - 0s - loss: 45.7825\n",
      "Epoch 113/150\n",
      "34/34 - 0s - loss: 45.9157\n",
      "Epoch 114/150\n",
      "34/34 - 0s - loss: 45.5260\n",
      "Epoch 115/150\n",
      "34/34 - 0s - loss: 45.9057\n",
      "Epoch 116/150\n",
      "34/34 - 0s - loss: 44.3037\n",
      "Epoch 117/150\n",
      "34/34 - 0s - loss: 44.3475\n",
      "Epoch 118/150\n",
      "34/34 - 0s - loss: 44.5714\n",
      "Epoch 119/150\n",
      "34/34 - 0s - loss: 43.3918\n",
      "Epoch 120/150\n",
      "34/34 - 0s - loss: 42.3458\n",
      "Epoch 121/150\n",
      "34/34 - 0s - loss: 44.4205\n",
      "Epoch 122/150\n",
      "34/34 - 0s - loss: 45.2765\n",
      "Epoch 123/150\n",
      "34/34 - 0s - loss: 44.1268\n",
      "Epoch 124/150\n",
      "34/34 - 0s - loss: 46.5663\n",
      "Epoch 125/150\n",
      "34/34 - 0s - loss: 43.6438\n",
      "Epoch 126/150\n",
      "34/34 - 0s - loss: 43.1622\n",
      "Epoch 127/150\n",
      "34/34 - 0s - loss: 44.1983\n",
      "Epoch 128/150\n",
      "34/34 - 0s - loss: 41.2471\n",
      "Epoch 129/150\n",
      "34/34 - 0s - loss: 42.1557\n",
      "Epoch 130/150\n",
      "34/34 - 0s - loss: 41.9816\n",
      "Epoch 131/150\n",
      "34/34 - 0s - loss: 43.6974\n",
      "Epoch 132/150\n",
      "34/34 - 0s - loss: 42.5318\n",
      "Epoch 133/150\n",
      "34/34 - 0s - loss: 44.4046\n",
      "Epoch 134/150\n",
      "34/34 - 0s - loss: 42.1835\n",
      "Epoch 135/150\n",
      "34/34 - 0s - loss: 41.3645\n",
      "Epoch 136/150\n",
      "34/34 - 0s - loss: 41.4624\n",
      "Epoch 137/150\n",
      "34/34 - 0s - loss: 40.0391\n",
      "Epoch 138/150\n",
      "34/34 - 0s - loss: 41.6241\n",
      "Epoch 139/150\n",
      "34/34 - 0s - loss: 39.4358\n",
      "Epoch 140/150\n",
      "34/34 - 0s - loss: 39.7296\n",
      "Epoch 141/150\n",
      "34/34 - 0s - loss: 41.0449\n",
      "Epoch 142/150\n",
      "34/34 - 0s - loss: 40.9736\n",
      "Epoch 143/150\n",
      "34/34 - 0s - loss: 40.1335\n",
      "Epoch 144/150\n",
      "34/34 - 0s - loss: 42.4196\n",
      "Epoch 145/150\n",
      "34/34 - 0s - loss: 38.7460\n",
      "Epoch 146/150\n",
      "34/34 - 0s - loss: 38.2779\n",
      "Epoch 147/150\n",
      "34/34 - 0s - loss: 40.7075\n",
      "Epoch 148/150\n",
      "34/34 - 0s - loss: 41.9191\n",
      "Epoch 149/150\n",
      "34/34 - 0s - loss: 39.8459\n",
      "Epoch 150/150\n",
      "34/34 - 0s - loss: 37.8464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x292c5bbdf40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 43.186, RMSE: 6.572\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "error = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f' % (error, np.sqrt(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 1) (167,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[23.657848 ],\n",
       "       [28.48399  ],\n",
       "       [34.380238 ],\n",
       "       [15.3872175],\n",
       "       [15.472857 ],\n",
       "       [19.365032 ],\n",
       "       [22.218601 ],\n",
       "       [15.869121 ],\n",
       "       [30.358822 ],\n",
       "       [14.649905 ],\n",
       "       [ 7.071918 ],\n",
       "       [27.77715  ],\n",
       "       [20.608631 ],\n",
       "       [19.76411  ],\n",
       "       [16.322803 ],\n",
       "       [15.501254 ],\n",
       "       [21.288609 ],\n",
       "       [23.294376 ],\n",
       "       [28.09621  ],\n",
       "       [22.895176 ],\n",
       "       [28.116299 ],\n",
       "       [ 7.201183 ],\n",
       "       [25.624271 ],\n",
       "       [19.051128 ],\n",
       "       [26.164028 ],\n",
       "       [22.97292  ],\n",
       "       [19.798183 ],\n",
       "       [22.599575 ],\n",
       "       [19.858852 ],\n",
       "       [21.133144 ],\n",
       "       [19.961796 ],\n",
       "       [27.637798 ],\n",
       "       [25.067104 ],\n",
       "       [30.192417 ],\n",
       "       [27.134655 ],\n",
       "       [21.649761 ],\n",
       "       [28.215824 ],\n",
       "       [ 8.592654 ],\n",
       "       [27.608913 ],\n",
       "       [28.18089  ],\n",
       "       [16.591328 ],\n",
       "       [13.94028  ],\n",
       "       [24.079243 ],\n",
       "       [24.73869  ],\n",
       "       [22.842228 ],\n",
       "       [26.367031 ],\n",
       "       [24.581287 ],\n",
       "       [11.008113 ],\n",
       "       [19.084301 ],\n",
       "       [20.747341 ],\n",
       "       [29.169064 ],\n",
       "       [28.253155 ],\n",
       "       [23.819927 ],\n",
       "       [28.27779  ],\n",
       "       [14.204261 ],\n",
       "       [20.42384  ],\n",
       "       [20.4586   ],\n",
       "       [18.361881 ],\n",
       "       [10.756137 ],\n",
       "       [22.719112 ],\n",
       "       [24.56728  ],\n",
       "       [ 8.392163 ],\n",
       "       [26.511814 ],\n",
       "       [20.983036 ],\n",
       "       [25.944096 ],\n",
       "       [25.249447 ],\n",
       "       [24.729832 ],\n",
       "       [26.552036 ],\n",
       "       [20.640736 ],\n",
       "       [26.19006  ],\n",
       "       [23.82423  ],\n",
       "       [24.845364 ],\n",
       "       [23.500072 ],\n",
       "       [18.914654 ],\n",
       "       [20.39526  ],\n",
       "       [ 8.830119 ],\n",
       "       [13.53255  ],\n",
       "       [27.427052 ],\n",
       "       [27.048588 ],\n",
       "       [13.408641 ],\n",
       "       [18.130398 ],\n",
       "       [18.273502 ],\n",
       "       [29.401157 ],\n",
       "       [26.048779 ],\n",
       "       [26.966915 ],\n",
       "       [24.288548 ],\n",
       "       [ 1.9955821],\n",
       "       [15.040927 ],\n",
       "       [20.884365 ],\n",
       "       [15.98733  ],\n",
       "       [16.263897 ],\n",
       "       [29.252079 ],\n",
       "       [29.424526 ],\n",
       "       [26.012959 ],\n",
       "       [36.02979  ],\n",
       "       [23.876911 ],\n",
       "       [30.43118  ],\n",
       "       [20.401524 ],\n",
       "       [20.050373 ],\n",
       "       [18.25037  ],\n",
       "       [27.226467 ],\n",
       "       [30.107403 ],\n",
       "       [ 9.263011 ],\n",
       "       [24.14758  ],\n",
       "       [22.930683 ],\n",
       "       [16.672947 ],\n",
       "       [ 2.3574634],\n",
       "       [22.919247 ],\n",
       "       [15.745349 ],\n",
       "       [20.200108 ],\n",
       "       [25.58485  ],\n",
       "       [26.551136 ],\n",
       "       [27.787495 ],\n",
       "       [19.89677  ],\n",
       "       [30.377453 ],\n",
       "       [27.456028 ],\n",
       "       [31.538837 ],\n",
       "       [12.85356  ],\n",
       "       [22.107601 ],\n",
       "       [24.817928 ],\n",
       "       [18.886585 ],\n",
       "       [10.876544 ],\n",
       "       [31.017193 ],\n",
       "       [16.21539  ],\n",
       "       [28.509052 ],\n",
       "       [30.085087 ],\n",
       "       [27.94572  ],\n",
       "       [22.898922 ],\n",
       "       [31.147778 ],\n",
       "       [22.77232  ],\n",
       "       [23.337994 ],\n",
       "       [19.553608 ],\n",
       "       [29.01675  ],\n",
       "       [27.813587 ],\n",
       "       [20.559902 ],\n",
       "       [20.313564 ],\n",
       "       [25.178707 ],\n",
       "       [16.26221  ],\n",
       "       [16.049145 ],\n",
       "       [12.539813 ],\n",
       "       [11.737666 ],\n",
       "       [12.12358  ],\n",
       "       [23.753597 ],\n",
       "       [14.583018 ],\n",
       "       [17.507282 ],\n",
       "       [14.164126 ],\n",
       "       [21.16261  ],\n",
       "       [25.621738 ],\n",
       "       [11.236859 ],\n",
       "       [24.206165 ],\n",
       "       [22.402279 ],\n",
       "       [25.15939  ],\n",
       "       [18.675655 ],\n",
       "       [16.171124 ],\n",
       "       [18.367756 ],\n",
       "       [27.499004 ],\n",
       "       [19.321918 ],\n",
       "       [22.921192 ],\n",
       "       [22.24355  ],\n",
       "       [29.28632  ],\n",
       "       [25.056194 ],\n",
       "       [26.099102 ],\n",
       "       [14.26855  ],\n",
       "       [14.563083 ],\n",
       "       [26.317112 ],\n",
       "       [26.519985 ],\n",
       "       [26.212215 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions.shape, y_test.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.10074230340162527 43.185615607128014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error , r2_score , accuracy_score\n",
    "acc = r2_score(predictions , y_test)\n",
    "mse = mean_squared_error(predictions , y_test)\n",
    "#accuracy = accuracy_score(predictions , y_test)  not supported\n",
    "\n",
    "print(acc, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.6, 22.8, 28.5, 13.4, 13.9, 19.6, 23.1, 23.1, 30.1, 15.4,  8.5,\n",
       "       33.8, 50. , 17.8, 20.6, 21.9, 16.6, 24.6, 23.6, 22.7, 50. , 13.1,\n",
       "       23.6, 13.8, 29.9, 21.7, 22.3, 18.2, 23.4, 16.8, 18.8, 23. , 23.8,\n",
       "       23.1, 28. , 24.7, 22. , 12. , 37.2, 22.9, 19.3, 12.3, 46.7, 29. ,\n",
       "       20.1, 22. , 19.4, 17.2, 19.3, 20. , 23.9, 35.4, 29.4, 50. , 11.7,\n",
       "       18.5, 22.6, 21.4, 17.8, 26.6, 18.9,  8.3, 11.9, 19.4, 24.8, 20.7,\n",
       "       25. , 33.1, 22.4, 21.6, 25. , 20.7, 19.6, 19.9, 15.2,  7.5, 14.1,\n",
       "       25. , 29. , 10.8, 16.1, 15.1, 50. , 33.2, 50. , 20.1,  7. , 20.1,\n",
       "       18.1, 23.2, 10.9, 22.3, 21.9, 23.3, 31.6, 19.5, 37.6, 21.8, 14.5,\n",
       "       13.1, 33. , 34.6,  8.8, 23.4, 23.7, 10.2, 13.8, 25. , 17.4, 15.3,\n",
       "       26.6, 42.8, 31. , 21.7, 50. , 26.7, 33.3, 13.4, 18. , 37. , 21.4,\n",
       "       13.9, 45.4, 14.6, 20.6, 24.8, 29.1, 24.4, 28.2, 19.6, 17.6, 18.4,\n",
       "       23.9, 34.7, 21.7, 23. , 20.1, 19.7, 17.1, 11.8,  9.7, 12.7, 23.1,\n",
       "       13.8, 21.4, 11.3, 18.4, 22. ,  8.8, 28.6, 22.7, 24.8, 19.1, 14.3,\n",
       "       17. , 33.4, 14.9, 19.7, 24. , 44.8, 29.6, 22.9, 14.4, 16.7, 30.5,\n",
       "       30.3, 25. ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 27.335\n"
     ]
    }
   ],
   "source": [
    "row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
